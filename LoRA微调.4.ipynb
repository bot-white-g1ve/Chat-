{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204ab41f-4a43-47ac-823e-9ca89a5e8228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===Import Tokenizer=== \n",
      " ===Import Model=== \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ffc243d4274923bfc59f54b52ff83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 载入模型\n",
    "print(\" ===Import Tokenizer=== \")\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('/ssd/xthu/ChatGLM2-6B/chatglm2-6b', trust_remote_code=True)\n",
    "\n",
    "print(\" ===Import Model=== \")\n",
    "model_origin = AutoModel.from_pretrained(\"/ssd/xthu/ChatGLM2-6B/chatglm2-6b\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e531fd-a94a-4a27-9a6d-e84de6dbc12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===Set Global Parameters=== \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\" ===Set Global Parameters=== \")\n",
    "lr = 1e-6\n",
    "lora_r=8\n",
    "device=torch.device(\"cuda\")\n",
    "batch_size=2\n",
    "total_epochs=500\n",
    "model_output_dir=\"LoRA_pretrained\"\n",
    "gradient_accumulation_steps=2 # After how many times of loading, one gradient is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84796d15-0a91-4bf5-9262-74e79dbdeb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===Special Token=== \n",
      "eos:  2\n",
      "pad:  0\n"
     ]
    }
   ],
   "source": [
    "print(\" ===Special Token=== \")\n",
    "eos = tokenizer.get_command(\"<eos>\")\n",
    "pad = tokenizer.get_command(\"<pad>\")\n",
    "print(\"eos: \", eos)\n",
    "print(\"pad: \", pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace7830a-79d8-4ac4-9146-15c27ffcb81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===Import Peft=== \n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.0312\n",
      "Random parameter data type: torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(\" ===Import Peft=== \")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "peft_config=LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=lora_r,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "model = get_peft_model(model_origin, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "model = model.to(device)\n",
    "device_ids = [0, 1, 2, 3]\n",
    "# model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora' in name.lower():  # 检查参数名中是否包含'lora'\n",
    "        param.data = param.data.float()  # 转换为float32\n",
    "\n",
    "params = list(model.parameters())\n",
    "import random\n",
    "random_param = random.choice(params)\n",
    "print(f'Random parameter data type: {random_param.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d62cd-9917-4816-a202-845b54378860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG：for LoRA NaN (NON-USE)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设 model 已经是您加载的模型实例\n",
    "# 遍历模型的所有参数\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} - DataType: {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e65626-e56e-4210-b196-9913d2d8c7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): ChatGLMForConditionalGeneration(\n",
      "      (transformer): ChatGLMModel(\n",
      "        (embedding): Embedding(\n",
      "          (word_embeddings): Embedding(65024, 4096)\n",
      "        )\n",
      "        (rotary_pos_emb): RotaryEmbedding()\n",
      "        (encoder): GLMTransformer(\n",
      "          (layers): ModuleList(\n",
      "            (0-27): 28 x GLMBlock(\n",
      "              (input_layernorm): RMSNorm()\n",
      "              (self_attention): SelfAttention(\n",
      "                (query_key_value): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=4096, out_features=4608, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=4608, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (core_attention): CoreAttention(\n",
      "                  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (post_attention_layernorm): RMSNorm()\n",
      "              (mlp): MLP(\n",
      "                (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)\n",
      "                (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (final_layernorm): RMSNorm()\n",
      "        )\n",
      "        (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# DEBUG：for LoRA NaN (NON-USE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c19f19d-034a-47cf-9a68-89464757bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===Build Dataset=== \n",
      "Data loaded, size: 21\n",
      "A random data example: {'index': 13, 'question': '学马叫', 'answer': '喵喵喵'}\n",
      "A random preprocessed data example: {'input_ids': tensor([64790, 64792,   790, 30951,   517, 30910, 30939, 30996,    13,    13,\n",
      "        54761, 31211, 39701,    13,    13, 55437, 31211, 36474, 54591, 59000,\n",
      "            2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100, 36474, 54591, 59000,\n",
      "            2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])}\n",
      "The length of input ids is 200\n",
      "The length of labels is 200\n"
     ]
    }
   ],
   "source": [
    "print(\" ===Build Dataset=== \")\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, max_source_length, max_target_length) -> None:\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "        self.max_seq_length = self.max_source_length + self.max_target_length\n",
    "\n",
    "        df = pd.read_csv(data_path, delimiter=',', encoding='gbk')\n",
    "        self.datas = [\n",
    "            {'index': idx, 'question': row['Question'], 'answer': row['Answer']}\n",
    "            for idx, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        print(\"Data loaded, size:\", len(self.datas))\n",
    "        if len(self.datas) > 0:\n",
    "            print(\"A random data example:\", self.datas[random.randint(0, len(self.datas)-1)])\n",
    "\n",
    "    def preprocess(self, question, answer):\n",
    "        prompt = self.tokenizer.build_prompt(question, None)\n",
    "\n",
    "        q_ids = self.tokenizer.encode(text=prompt, add_special_tokens=True, truncation=True,\n",
    "                                      max_length=self.max_source_length)\n",
    "\n",
    "        a_ids = self.tokenizer.encode(text=answer, add_special_tokens=False, truncation=True,\n",
    "                                      max_length=self.max_target_length)\n",
    "\n",
    "        q_len = len(q_ids)\n",
    "        input_ids = q_ids + a_ids + [eos]\n",
    "        labels = [-100] * q_len + a_ids + [eos]\n",
    "        # padding after is needed because of dataloader requires same length\n",
    "        pad_len = self.max_seq_length - len(input_ids)\n",
    "        input_ids = input_ids + [pad] * pad_len\n",
    "        labels = labels + [-100] * pad_len\n",
    "        return input_ids, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_data = self.datas[index]\n",
    "\n",
    "        input_ids, labels = self.preprocess(item_data['question'],item_data['answer'])\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.LongTensor(np.array(input_ids)),\n",
    "            \"labels\": torch.LongTensor(np.array(labels))\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "\n",
    "train_dataset = QADataset(\"../角色Dataset/喵喵喵.csv\", tokenizer, 100, 100)\n",
    "\n",
    "from pprint import pprint\n",
    "random_data = train_dataset[random.randint(0, len(train_dataset)-1)]\n",
    "print(f\"A random preprocessed data example: {random_data}\")\n",
    "print(f\"The length of input ids is {len(random_data['input_ids'])}\")\n",
    "print(f\"The length of labels is {len(random_data['labels'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1623fe-faae-485c-a613-3052d5f350a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "def train_epoch(epoch, model, device, loader, optimizer, gradient_accumulation_steps):\n",
    "    model.train()\n",
    "    previous_time = time.time()\n",
    "    for index, data in enumerate(tqdm(loader, file=sys.stdout, desc=\"Train Epoch: \" + str(epoch))):\n",
    "        input_ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "        labels = data['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        if (torch.isnan(loss)):\n",
    "            tqdm.write(\" !!!NaN encountered!!! \")\n",
    "            save_checkpoint(epoch, optimizer, model, model_output_dir, True)\n",
    "            raise Exception(\"NaN error\")\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        if (index % gradient_accumulation_steps == 0 and index != 0) or index == len(loader) - 1:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            current_time = time.time()\n",
    "            tqdm.write(f\"In epoch {epoch}, the {index} times of loading, the current loss is {loss.item()}\")\n",
    "            tqdm.write(f\"For {gradient_accumulation_steps} steps, the time used: {current_time-previous_time}\")\n",
    "            previous_time = current_time\n",
    "\n",
    "def train(total_epochs, model, device, train_loader, optimizer, gradient_accumulation_steps, model_output_dir):\n",
    "    for epoch in range(total_epochs):\n",
    "        print(f\" ===Epoch {epoch}=== \")\n",
    "        train_epoch(epoch, model, device, train_loader, optimizer, gradient_accumulation_steps)\n",
    "        save_checkpoint(epoch, optimizer, model, model_output_dir, False)\n",
    "\n",
    "def save_checkpoint(epoch, optimizer, model, model_output_dir, error):\n",
    "    print(\" ===Save model and Checkpoint=== \")\n",
    "    print(\"Save To \", model_output_dir)\n",
    "    model.save_pretrained(model_output_dir)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'error': error,\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, os.path.join(model_output_dir, \"latest_checkpoint\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6454c-05e0-4a17-b47d-6ff073299435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "print(\" ===prepare dataloader=== \")\n",
    "dataloader_params = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 0,\n",
    "}\n",
    "print(\"the batch size: \", batch_size)\n",
    "train_loader = DataLoader(train_dataset, **dataloader_params)\n",
    "\n",
    "print(\" ===prepare optimizer=== \")\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "print(\" !!!Start Training!!! \")\n",
    "train(total_epochs, model, device, train_loader, optimizer, gradient_accumulation_steps, model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f010e0ef-36c6-4989-b0ed-8a755128afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found in model parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查nan并找出哪个参数（NON-USE）\n",
    "import torch\n",
    "\n",
    "def check_for_nan(model):\n",
    "    nan_found = False\n",
    "    for name, param in model.named_parameters():\n",
    "        if torch.isnan(param).any():\n",
    "            print(f\"NaN detected in parameter: {name}\")\n",
    "            nan_found = True\n",
    "    if not nan_found:\n",
    "        print(\"No NaN values found in model parameters.\")\n",
    "    return nan_found\n",
    "\n",
    "check_for_nan(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23cff181-670e-4adc-83c2-ab8c7ea49867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): ChatGLMForConditionalGeneration(\n",
       "      (transformer): ChatGLMModel(\n",
       "        (embedding): Embedding(\n",
       "          (word_embeddings): Embedding(65024, 4096)\n",
       "        )\n",
       "        (rotary_pos_emb): RotaryEmbedding()\n",
       "        (encoder): GLMTransformer(\n",
       "          (layers): ModuleList(\n",
       "            (0-27): 28 x GLMBlock(\n",
       "              (input_layernorm): RMSNorm()\n",
       "              (self_attention): SelfAttention(\n",
       "                (query_key_value): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=4096, out_features=4608, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4608, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (core_attention): CoreAttention(\n",
       "                  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              )\n",
       "              (post_attention_layernorm): RMSNorm()\n",
       "              (mlp): MLP(\n",
       "                (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)\n",
       "                (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (final_layernorm): RMSNorm()\n",
       "        )\n",
       "        (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from peft import PeftConfig, PeftModel, LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 记得先加载global params\n",
    "\n",
    "# 记得先加载模型\n",
    "\n",
    "lora_config=PeftConfig.from_pretrained(model_output_dir)\n",
    "model = PeftModel.from_pretrained(model_origin, model_output_dir)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "checkpoint = torch.load(os.path.join(model_output_dir, \"latest_checkpoint\"))\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0764be8-ce0f-4218-a372-27555d3c7b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat喵喵喵： 喵喵喵\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"学猫叫\", history=[])\n",
    "print(\"Chat喵喵喵：\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0dfc2c0-d914-4bbb-85de-dc51fd594077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): ChatGLMForConditionalGeneration(\n",
      "      (transformer): ChatGLMModel(\n",
      "        (embedding): Embedding(\n",
      "          (word_embeddings): Embedding(65024, 4096)\n",
      "        )\n",
      "        (rotary_pos_emb): RotaryEmbedding()\n",
      "        (encoder): GLMTransformer(\n",
      "          (layers): ModuleList(\n",
      "            (0-27): 28 x GLMBlock(\n",
      "              (input_layernorm): RMSNorm()\n",
      "              (self_attention): SelfAttention(\n",
      "                (query_key_value): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=4096, out_features=4608, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=4608, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (core_attention): CoreAttention(\n",
      "                  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (post_attention_layernorm): RMSNorm()\n",
      "              (mlp): MLP(\n",
      "                (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)\n",
      "                (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (final_layernorm): RMSNorm()\n",
      "        )\n",
      "        (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65778e3d-0862-41fb-ac19-1c47d0c7e183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.transformer.embedding.word_embeddings.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.0.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.1.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.2.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.3.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.4.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.5.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.6.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.7.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.8.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.9.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.10.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.11.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.12.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.13.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.14.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.15.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.16.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.17.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.18.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.19.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.20.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.21.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.22.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.23.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.24.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.25.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.26.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.input_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.base_layer.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.base_layer.bias - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_A.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.self_attention.query_key_value.lora_B.default.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.self_attention.dense.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.post_attention_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.mlp.dense_h_to_4h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.layers.27.mlp.dense_4h_to_h.weight - DataType: torch.float16\n",
      "base_model.model.transformer.encoder.final_layernorm.weight - DataType: torch.float16\n",
      "base_model.model.transformer.output_layer.weight - DataType: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# DEBUG：for LoRA NaN (NON-USE)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设 model 已经是您加载的模型实例\n",
    "# 遍历模型的所有参数\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} - DataType: {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28094611-d1c2-4e60-ae2a-fd5e3b5474b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
